import torch
from torch.utils.data import Dataset
import cv2
import numpy as np
import os
import random
from glob import glob

class DefectDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.image_paths = []
        self.labels = []
        self.class_map = {}  # e.g., {'Porosity': 0, 'Crack': 1, ...}
        self.transform = transform

        for idx, defect_type in enumerate(sorted(os.listdir(root_dir))):
            class_dir = os.path.join(root_dir, defect_type)
            if os.path.isdir(class_dir):
                self.class_map[defect_type] = idx
                for img_path in glob(os.path.join(class_dir, "*.jpg")):
                    self.image_paths.append(img_path)
                    self.labels.append(idx)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, index):
        img_path = self.image_paths[index]
        label = self.labels[index]

        # --- Load image and convert to grayscale ---
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

        # --- Step 1: CLAHE ---
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        img = clahe.apply(img)

        # --- Step 2: Non-local means denoising ---
        img = cv2.fastNlMeansDenoising(img, h=10, templateWindowSize=7, searchWindowSize=21)

        # --- Step 3: Affine transform (±15° rotation, 0.9–1.1 scale) ---
        h, w = img.shape
        center = (w // 2, h // 2)
        angle = np.random.uniform(-15, 15)
        scale = np.random.uniform(0.9, 1.1)
        M = cv2.getRotationMatrix2D(center, angle, scale)
        img = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

        # --- Step 4: Phong highlight simulation ---
        norm_img = img.astype(np.float32) / 255.0
        gx = cv2.Sobel(norm_img, cv2.CV_32F, 1, 0, ksize=5)
        gy = cv2.Sobel(norm_img, cv2.CV_32F, 0, 1, ksize=5)
        normal = np.dstack((-gx, -gy, np.ones_like(norm_img)))
        normal /= np.clip(np.linalg.norm(normal, axis=2, keepdims=True), 1e-6, None)

        light = np.array([1, -1, 1]) / np.sqrt(3)
        dot = np.clip(np.sum(normal * light, axis=2), 0, 1)
        specular = (dot ** 20) * 0.5
        phong_img = np.clip(norm_img + specular, 0, 1)
        img = (phong_img * 255).astype(np.uint8)

        # Normalize and expand dims for CNN input
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, axis=0)  # (1, H, W)

        return torch.tensor(img, dtype=torch.float32), torch.tensor(label)

